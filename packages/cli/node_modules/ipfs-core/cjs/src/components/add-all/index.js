'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var ipfsUnixfsImporter = require('ipfs-unixfs-importer');
var normaliseInputMultiple = require('ipfs-core-utils/files/normalise-input-multiple');
var utils = require('./utils.js');
var itPipe = require('it-pipe');
var withTimeoutOption = require('ipfs-core-utils/with-timeout-option');
var mergeOpts = require('merge-options');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

var mergeOpts__default = /*#__PURE__*/_interopDefaultLegacy(mergeOpts);

const mergeOptions = mergeOpts__default["default"].bind({ ignoreUndefined: true });
function createAddAll({repo, preload, options}) {
  const isShardingEnabled = options && options.sharding;
  async function* addAll(source, options = {}) {
    const opts = mergeOptions({
      shardSplitThreshold: isShardingEnabled ? 1000 : Infinity,
      strategy: 'balanced'
    }, options, { ...utils.parseChunkerString(options.chunker) });
    if (opts.hashAlg && opts.hashAlg !== 'sha2-256' && opts.cidVersion !== 1) {
      opts.cidVersion = 1;
    }
    if (opts.trickle) {
      opts.strategy = 'trickle';
    }
    if (opts.strategy === 'trickle') {
      opts.leafType = 'raw';
      opts.reduceSingleLeafToSelf = false;
    }
    if (opts.cidVersion > 0 && opts.rawLeaves === undefined) {
      opts.rawLeaves = true;
    }
    if (opts.hashAlg !== undefined && opts.rawLeaves === undefined) {
      opts.rawLeaves = true;
    }
    delete opts.trickle;
    const totals = {};
    if (opts.progress) {
      const prog = opts.progress;
      opts.progress = (bytes, path) => {
        if (!totals[path]) {
          totals[path] = 0;
        }
        totals[path] += bytes;
        prog(totals[path], path);
      };
    }
    const iterator = itPipe.pipe(normaliseInputMultiple.normaliseInput(source), source => ipfsUnixfsImporter.importer(source, repo.blocks, {
      ...opts,
      pin: false
    }), transformFile(opts), preloadFile(preload, opts), pinFile(repo, opts));
    const releaseLock = await repo.gcLock.readLock();
    try {
      for await (const added of iterator) {
        delete totals[added.path];
        yield added;
      }
    } finally {
      releaseLock();
    }
  }
  return withTimeoutOption.withTimeoutOption(addAll);
}
function transformFile(opts) {
  async function* transformFile(source) {
    for await (const file of source) {
      let cid = file.cid;
      if (opts.cidVersion === 1) {
        cid = cid.toV1();
      }
      let path = file.path ? file.path : cid.toString();
      if (opts.wrapWithDirectory && !file.path) {
        path = '';
      }
      yield {
        path,
        cid: cid,
        size: file.size,
        mode: file.unixfs && file.unixfs.mode,
        mtime: file.unixfs && file.unixfs.mtime
      };
    }
  }
  return transformFile;
}
function preloadFile(preload, opts) {
  async function* maybePreloadFile(source) {
    for await (const file of source) {
      const isRootFile = !file.path || opts.wrapWithDirectory ? file.path === '' : !file.path.includes('/');
      const shouldPreload = isRootFile && !opts.onlyHash && opts.preload !== false;
      if (shouldPreload) {
        preload(file.cid);
      }
      yield file;
    }
  }
  return maybePreloadFile;
}
function pinFile(repo, opts) {
  async function* maybePinFile(source) {
    for await (const file of source) {
      const isRootDir = !(file.path && file.path.includes('/'));
      const shouldPin = (opts.pin == null ? true : opts.pin) && isRootDir && !opts.onlyHash;
      if (shouldPin) {
        await repo.pins.pinRecursively(file.cid);
      }
      yield file;
    }
  }
  return maybePinFile;
}

exports.createAddAll = createAddAll;
