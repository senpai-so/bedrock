import { importer } from 'ipfs-unixfs-importer';
import { normaliseInput } from 'ipfs-core-utils/files/normalise-input-multiple';
import { parseChunkerString } from './utils.js';
import { pipe } from 'it-pipe';
import { withTimeoutOption } from 'ipfs-core-utils/with-timeout-option';
import mergeOpts from 'merge-options';
const mergeOptions = mergeOpts.bind({ ignoreUndefined: true });
export function createAddAll({repo, preload, options}) {
  const isShardingEnabled = options && options.sharding;
  async function* addAll(source, options = {}) {
    const opts = mergeOptions({
      shardSplitThreshold: isShardingEnabled ? 1000 : Infinity,
      strategy: 'balanced'
    }, options, { ...parseChunkerString(options.chunker) });
    if (opts.hashAlg && opts.hashAlg !== 'sha2-256' && opts.cidVersion !== 1) {
      opts.cidVersion = 1;
    }
    if (opts.trickle) {
      opts.strategy = 'trickle';
    }
    if (opts.strategy === 'trickle') {
      opts.leafType = 'raw';
      opts.reduceSingleLeafToSelf = false;
    }
    if (opts.cidVersion > 0 && opts.rawLeaves === undefined) {
      opts.rawLeaves = true;
    }
    if (opts.hashAlg !== undefined && opts.rawLeaves === undefined) {
      opts.rawLeaves = true;
    }
    delete opts.trickle;
    const totals = {};
    if (opts.progress) {
      const prog = opts.progress;
      opts.progress = (bytes, path) => {
        if (!totals[path]) {
          totals[path] = 0;
        }
        totals[path] += bytes;
        prog(totals[path], path);
      };
    }
    const iterator = pipe(normaliseInput(source), source => importer(source, repo.blocks, {
      ...opts,
      pin: false
    }), transformFile(opts), preloadFile(preload, opts), pinFile(repo, opts));
    const releaseLock = await repo.gcLock.readLock();
    try {
      for await (const added of iterator) {
        delete totals[added.path];
        yield added;
      }
    } finally {
      releaseLock();
    }
  }
  return withTimeoutOption(addAll);
}
function transformFile(opts) {
  async function* transformFile(source) {
    for await (const file of source) {
      let cid = file.cid;
      if (opts.cidVersion === 1) {
        cid = cid.toV1();
      }
      let path = file.path ? file.path : cid.toString();
      if (opts.wrapWithDirectory && !file.path) {
        path = '';
      }
      yield {
        path,
        cid: cid,
        size: file.size,
        mode: file.unixfs && file.unixfs.mode,
        mtime: file.unixfs && file.unixfs.mtime
      };
    }
  }
  return transformFile;
}
function preloadFile(preload, opts) {
  async function* maybePreloadFile(source) {
    for await (const file of source) {
      const isRootFile = !file.path || opts.wrapWithDirectory ? file.path === '' : !file.path.includes('/');
      const shouldPreload = isRootFile && !opts.onlyHash && opts.preload !== false;
      if (shouldPreload) {
        preload(file.cid);
      }
      yield file;
    }
  }
  return maybePreloadFile;
}
function pinFile(repo, opts) {
  async function* maybePinFile(source) {
    for await (const file of source) {
      const isRootDir = !(file.path && file.path.includes('/'));
      const shouldPin = (opts.pin == null ? true : opts.pin) && isRootDir && !opts.onlyHash;
      if (shouldPin) {
        await repo.pins.pinRecursively(file.cid);
      }
      yield file;
    }
  }
  return maybePinFile;
}