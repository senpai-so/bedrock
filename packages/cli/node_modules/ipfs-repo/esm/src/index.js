import _get from 'just-safe-get';
import debug from 'debug';
import errCode from 'err-code';
import * as migrator from 'ipfs-repo-migrations';
import bytes from 'bytes';
import merge from 'merge-options';
import * as CONSTANTS from './constants.js';
import { version } from './version.js';
import { config } from './config.js';
import { spec } from './spec.js';
import { apiAddr } from './api-addr.js';
import { createIdStore } from './idstore.js';
import defaultOptions from './default-options.js';
import defaultDatastore from './default-datastore.js';
import * as ERRORS from './errors.js';
import { PinManager } from './pin-manager.js';
import { createPinnedBlockstore } from './pinned-blockstore.js';
import mortice from 'mortice';
import { gc } from './gc.js';
const log = debug('ipfs:repo');
const noLimit = Number.MAX_SAFE_INTEGER;
const AUTO_MIGRATE_CONFIG_KEY = 'repoAutoMigrate';
class Repo {
  constructor(path, loadCodec, backends, options) {
    if (typeof path !== 'string') {
      throw new Error('missing repo path');
    }
    if (typeof loadCodec !== 'function') {
      throw new Error('missing codec loader');
    }
    this.options = merge(defaultOptions, options);
    this.closed = true;
    this.path = path;
    this.root = backends.root;
    this.datastore = backends.datastore;
    this.keys = backends.keys;
    const blockstore = backends.blocks;
    const pinstore = backends.pins;
    this.pins = new PinManager({
      pinstore,
      blockstore,
      loadCodec
    });
    const pinnedBlockstore = createPinnedBlockstore(this.pins, blockstore);
    this.blocks = createIdStore(pinnedBlockstore);
    this.version = version(this.root);
    this.config = config(this.root);
    this.spec = spec(this.root);
    this.apiAddr = apiAddr(this.root);
    this.gcLock = mortice(path, { singleProcess: this.options.repoOwner !== false });
    this.gc = gc({
      gcLock: this.gcLock,
      pins: this.pins,
      blockstore: this.blocks,
      root: this.root,
      loadCodec
    });
  }
  async init(config) {
    log('initializing at: %s', this.path);
    await this._openRoot();
    await this.config.replace(buildConfig(config));
    await this.spec.set(buildDatastoreSpec(config));
    await this.version.set(CONSTANTS.repoVersion);
  }
  async isInitialized() {
    if (!this.closed) {
      return true;
    }
    try {
      await this._openRoot();
      await this._checkInitialized();
      await this.root.close();
      return true;
    } catch (err) {
      return false;
    }
  }
  async open() {
    if (!this.closed) {
      throw errCode(new Error('repo is already open'), ERRORS.ERR_REPO_ALREADY_OPEN);
    }
    log('opening at: %s', this.path);
    try {
      await this._openRoot();
      await this._checkInitialized();
      this._lockfile = await this._openLock();
      log('acquired repo.lock');
      const isCompatible = await this.version.check(CONSTANTS.repoVersion);
      if (!isCompatible) {
        if (await this._isAutoMigrationEnabled()) {
          await this._migrate(CONSTANTS.repoVersion, {
            root: this.root,
            datastore: this.datastore,
            pins: this.pins.pinstore,
            blocks: this.pins.blockstore,
            keys: this.keys
          });
        } else {
          throw new ERRORS.InvalidRepoVersionError('Incompatible repo versions. Automatic migrations disabled. Please migrate the repo manually.');
        }
      }
      log('creating datastore');
      await this.datastore.open();
      log('creating blocks');
      await this.blocks.open();
      log('creating keystore');
      await this.keys.open();
      log('creating pins');
      await this.pins.pinstore.open();
      this.closed = false;
      log('all opened');
    } catch (err) {
      if (this._lockfile) {
        try {
          await this._closeLock();
          this._lockfile = null;
        } catch (err2) {
          log('error removing lock', err2);
        }
      }
      throw err;
    }
  }
  async _openRoot() {
    try {
      await this.root.open();
    } catch (err) {
      if (err.message !== 'Already open') {
        throw err;
      }
    }
  }
  async _openLock() {
    const lockfile = await this.options.repoLock.lock(this.path);
    if (typeof lockfile.close !== 'function') {
      throw errCode(new Error('Locks must have a close method'), 'ERR_NO_CLOSE_FUNCTION');
    }
    return lockfile;
  }
  _closeLock() {
    return this._lockfile && this._lockfile.close();
  }
  async _checkInitialized() {
    log('init check');
    let config;
    try {
      [config] = await Promise.all([
        this.config.exists(),
        this.spec.exists(),
        this.version.exists()
      ]);
    } catch (err) {
      if (err.code === 'ERR_NOT_FOUND') {
        throw errCode(new Error('repo is not initialized yet'), ERRORS.ERR_REPO_NOT_INITIALIZED, { path: this.path });
      }
      throw err;
    }
    if (!config) {
      throw errCode(new Error('repo is not initialized yet'), ERRORS.ERR_REPO_NOT_INITIALIZED, { path: this.path });
    }
  }
  async close() {
    if (this.closed) {
      throw errCode(new Error('repo is already closed'), ERRORS.ERR_REPO_ALREADY_CLOSED);
    }
    log('closing at: %s', this.path);
    try {
      await this.apiAddr.delete();
    } catch (err) {
      if (err.code !== ERRORS.ERR_REPO_NOT_INITIALIZED && !err.message.startsWith('ENOENT')) {
        throw err;
      }
    }
    await Promise.all([
      this.root,
      this.blocks,
      this.keys,
      this.datastore,
      this.pins.pinstore
    ].map(store => store && store.close()));
    log('unlocking');
    this.closed = true;
    await this._closeLock();
  }
  exists() {
    return this.version.exists();
  }
  async stat() {
    if (this.datastore && this.keys) {
      const [storageMax, blocks, version, datastore, keys] = await Promise.all([
        this._storageMaxStat(),
        this._blockStat(),
        this.version.get(),
        getSize(this.datastore),
        getSize(this.keys)
      ]);
      const size = blocks.size + datastore + keys;
      return {
        repoPath: this.path,
        storageMax,
        version: version,
        numObjects: blocks.count,
        repoSize: size
      };
    }
    throw errCode(new Error('repo is not initialized yet'), ERRORS.ERR_REPO_NOT_INITIALIZED, { path: this.path });
  }
  async _isAutoMigrationEnabled() {
    if (this.options.autoMigrate !== undefined) {
      return this.options.autoMigrate;
    }
    let autoMigrateConfig;
    try {
      autoMigrateConfig = await this.config.get(AUTO_MIGRATE_CONFIG_KEY);
    } catch (e) {
      if (e.code === ERRORS.NotFoundError.code) {
        autoMigrateConfig = true;
      } else {
        throw e;
      }
    }
    return autoMigrateConfig;
  }
  async _migrate(toVersion, backends) {
    const currentRepoVersion = await this.version.get();
    if (currentRepoVersion > toVersion) {
      log(`reverting to version ${ toVersion }`);
      return migrator.revert(this.path, backends, this.options, toVersion, {
        ignoreLock: true,
        onProgress: this.options.onMigrationProgress
      });
    } else {
      log(`migrating to version ${ toVersion }`);
      return migrator.migrate(this.path, backends, this.options, toVersion, {
        ignoreLock: true,
        onProgress: this.options.onMigrationProgress
      });
    }
  }
  async _storageMaxStat() {
    try {
      const max = await this.config.get('Datastore.StorageMax');
      return BigInt(bytes(max));
    } catch (err) {
      return BigInt(noLimit);
    }
  }
  async _blockStat() {
    let count = BigInt(0);
    let size = BigInt(0);
    if (this.blocks) {
      for await (const {key, value} of this.blocks.query({})) {
        count += BigInt(1);
        size += BigInt(value.byteLength);
        size += BigInt(key.bytes.byteLength);
      }
    }
    return {
      count,
      size
    };
  }
}
async function getSize(datastore) {
  let sum = BigInt(0);
  for await (const block of datastore.query({})) {
    sum += BigInt(block.value.byteLength);
    sum += BigInt(block.key.uint8Array().byteLength);
  }
  return sum;
}
export function createRepo(path, loadCodec, backends, options) {
  return new Repo(path, loadCodec, backends, options);
}
function buildConfig(_config) {
  _config.Datastore = Object.assign({}, defaultDatastore, _get(_config, 'datastore'));
  return _config;
}
function buildDatastoreSpec(_config) {
  const spec = {
    ...defaultDatastore.Spec,
    ..._get(_config, 'Datastore.Spec')
  };
  return {
    type: spec.type,
    mounts: spec.mounts.map(mounting => ({
      mountpoint: mounting.mountpoint,
      type: mounting.child.type,
      path: mounting.child.path,
      shardFunc: mounting.child.shardFunc
    }))
  };
}