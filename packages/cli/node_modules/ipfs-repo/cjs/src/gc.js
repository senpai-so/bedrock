'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var cid = require('multiformats/cid');
var debug = require('debug');
var errors = require('datastore-core/errors');
var parallelBatch = require('it-parallel-batch');
var itPipe = require('it-pipe');
var merge = require('it-merge');
var map = require('it-map');
var filter = require('it-filter');
var key = require('interface-datastore/key');
var base32 = require('multiformats/bases/base32');
var walkDag = require('./utils/walk-dag.js');

function _interopDefaultLegacy (e) { return e && typeof e === 'object' && 'default' in e ? e : { 'default': e }; }

var debug__default = /*#__PURE__*/_interopDefaultLegacy(debug);
var parallelBatch__default = /*#__PURE__*/_interopDefaultLegacy(parallelBatch);
var merge__default = /*#__PURE__*/_interopDefaultLegacy(merge);
var map__default = /*#__PURE__*/_interopDefaultLegacy(map);
var filter__default = /*#__PURE__*/_interopDefaultLegacy(filter);

const log = debug__default["default"]('ipfs:repo:gc');
const ERR_NOT_FOUND = errors.notFoundError().code;
const BLOCK_RM_CONCURRENCY = 256;
const MFS_ROOT_KEY = new key.Key('/local/filesroot');
function gc({gcLock, pins, blockstore, root, loadCodec}) {
  async function* gc() {
    const start = Date.now();
    log('Creating set of marked blocks');
    const release = await gcLock.writeLock();
    try {
      const markedSet = await createMarkedSet({
        pins,
        blockstore,
        root,
        loadCodec
      });
      const blockKeys = blockstore.queryKeys({});
      yield* deleteUnmarkedBlocks({ blockstore }, markedSet, blockKeys);
      log(`Complete (${ Date.now() - start }ms)`);
    } finally {
      release();
    }
  }
  return gc;
}
async function createMarkedSet({pins, blockstore, loadCodec, root}) {
  const mfsSource = async function* () {
    let mh;
    try {
      mh = await root.get(MFS_ROOT_KEY);
    } catch (err) {
      if (err.code === ERR_NOT_FOUND) {
        log('No blocks in MFS');
        return;
      }
      throw err;
    }
    const rootCid = cid.CID.decode(mh);
    yield rootCid;
    yield* walkDag.walkDag(rootCid, blockstore, loadCodec);
  }();
  const pinsSource = merge__default["default"](map__default["default"](pins.recursiveKeys(), ({cid}) => cid), pins.indirectKeys(), map__default["default"](pins.directKeys(), ({cid}) => cid), mfsSource);
  const output = new Set();
  for await (const cid of merge__default["default"](pinsSource, mfsSource)) {
    output.add(base32.base32.encode(cid.multihash.bytes));
  }
  return output;
}
async function* deleteUnmarkedBlocks({blockstore}, markedSet, blockKeys) {
  let blocksCount = 0;
  let removedBlocksCount = 0;
  const removeBlock = async cid => {
    return async function remove() {
      blocksCount++;
      try {
        const b32 = base32.base32.encode(cid.multihash.bytes);
        if (markedSet.has(b32)) {
          return null;
        }
        try {
          await blockstore.delete(cid);
          removedBlocksCount++;
        } catch (err) {
          return { err: new Error(`Could not delete block with CID ${ cid }: ${ err.message }`) };
        }
        return { cid };
      } catch (err) {
        const msg = `Could delete block with CID ${ cid }`;
        log(msg, err);
        return { err: new Error(msg + `: ${ err.message }`) };
      }
    };
  };
  yield* itPipe.pipe(parallelBatch__default["default"](map__default["default"](blockKeys, removeBlock), BLOCK_RM_CONCURRENCY), source => filter__default["default"](source, Boolean));
  log(`Marked set has ${ markedSet.size } unique blocks. Blockstore has ${ blocksCount } blocks. ` + `Deleted ${ removedBlocksCount } blocks.`);
}

exports.gc = gc;
